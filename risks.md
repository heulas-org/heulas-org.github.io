---
title: Risks
---
# Risks to End-Users

Below is a __non-exhaustive__ list of risks all software users are __exposed__ to.

## Hidden Patterns

Derivative, or __aggregate__, data is the initially-hidden information the software provider can __derive__ from how its users __interact__ with the software. This data, nearly always, is the __sole property__ of the software provider. Examples include:

* Users' __friends__, and friends-of-friends
* Hidden __demographic__ characteristics, such as __socio-economic__ standing
* Favourite places to __shop__ or __be__
* __Political__ bias
* __Sexual__ preference
* __Psychological__ profile

For example, this data can be used to intensifying __opinion bubbles__, and applying __psychological techniques__ according to the users' profile - by algorithmically encouraging __"doomscrolling"__ or by taking advantage of other psychological __vulnerabilities__ to keep users engaged. 

These outcomes usually happen __inadvertently__, when __time on the platform__ is optimized using __machine learning__ techniques. Another __common__ use of derivative data, is its __sale__ to third-parties in anonymized or aggregate form, which is seldom disclosed to users. Anonymized data is also open to __de-anonymizing__ techniques by cross-referencing __multiple__ data-sets.

## Future Analytics

A __related__ risk to derivative data is __future__ derivative data. Since disk __storage is cheap__, both raw and aggregate data are often stored for an __indefinite__ period of time. 

This means the owners of this data are __free to run__ improved analytics at any point in the future, as both __AI__ and __computing power__ become more __powerful__, and monetize, or otherwise utilize users' data __many__ times over, without users' knowledge or consent. 

Importantly, this means users are __exposed__ to unknown risks, especially in case the __political__ climate changes, leaving users __bare__ to future __scrutiny__ by yet-unknown actors.

## Addictive By Design

In a __landscape__ with multiple __competitive__ software platforms, and real-world __demands__, an increasing percentage of for-profit software is consciously making their products psychologically __addictive__.

This is done __without__ consideration for the __well-being__ of its end-users, and for the __sole purpose__ of keeping users engaged as much as possible, directly __paying__ for items, being exposed to __advertisements__, or otherwise performing actions __beneficial__ to the software provider.

This __environment__ has kicked-off a technological arms-race to the __bottom__ of the __brain-stem__, where software apps and services __compete__ against each other for __user-attention__ by appealing to increasingly basic __neurological__ and physiological responses.

## Opaque Data-Governance

Unless the software falls within a __well-regulated__ domain (such as medical, insurance and financial,) there are very __little assurances__ end-users get about how __their data__ is managed.

__Encrypting__, and otherwise securing, __information__ and communications users percieve as __private__ is purely __voluntary__ (depending on the jurisdiction,) and very often __lacking__. This includes:

* __Private__ messages
* __Email__ addresses
* __Physical__ addresses
* __Phone__ numbers
* Even __passwords__

This can, and does, lead to __information breaches__, both internal (e.g. __employees__ gaining access to private messages), and external (presenting an __easy target__ for hackers.)

## User-Data Ownership

Often, the software platform will __claim__ ownership to users' __original content__, be it __photos__, written pieces, etc. This can take __several forms__ from a very permissive license to full-ownership, but in the bottom line, it can __limit__ users from cross-publishing their content elsewhere, __monetizing__ it on another platform, or using it in other ways the software platform otherwise does not approve of. It also __opens the door__ for the software platform to __use__ the content in ways the users __did not__ intend.
